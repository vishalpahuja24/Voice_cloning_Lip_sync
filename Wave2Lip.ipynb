{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVB0Xn1g6ih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e56ae1-8fb4-41ff-9e61-1fd5c09905c3"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qciH4PsUazL_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd5668b-fbd6-49cc-d08b-b4065d547444"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee1fdae-8948-4c91-9339-fe4e2de9c4d1"
      },
      "source": [
        "!git clone https://github.com/Rudrabha/Wav2Lip.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 369, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 369 (delta 4), reused 3 (delta 1), pack-reused 360\u001b[K\n",
            "Receiving objects: 100% (369/369), 528.94 KiB | 4.07 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-19nzx8SamJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ffd2a2-24d9-4973-b209-496697a07b09"
      },
      "source": [
        "!ls /content/gdrive/MyDrive/Projects/Wave2Lip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input  weigths\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjzMPy_Sb0AI"
      },
      "source": [
        "!cp -ri \"/content/gdrive/MyDrive/Projects/Wave2Lip/weigths/wav2lip_gan.pth\" /content/Wav2Lip/checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooh28vw-Uvd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e59c872-e6fa-4800-f8ee-bb0382587dad"
      },
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.14.0\n",
            "Uninstalling tensorflow-2.14.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.14.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled tensorflow-2.14.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip install opencv-python==4.8.1.78"
      ],
      "metadata": {
        "id": "92ppmhNBdDbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49dCYlLdcK2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee374670-225d-4d7e-fb85-2a4bb5e769da"
      },
      "source": [
        "!cd Wav2Lip && pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting librosa==0.7.0 (from -r requirements.txt (line 1))\n",
            "  Using cached librosa-0.7.0.tar.gz (1.6 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.17.1 (from -r requirements.txt (line 2))\n",
            "  Using cached numpy-1.17.1.zip (6.5 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-contrib-python>=4.2.0.34 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.8.0.76)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.1.0.25 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.1.0.25\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey_bN4M6X_95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fe7045-b2f5-451e-e842-d3c6015341bb"
      },
      "source": [
        "!wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"Wav2Lip/face_detection/detection/sfd/s3fd.pth\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-02 19:21:44--  https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\n",
            "Resolving www.adrianbulat.com (www.adrianbulat.com)... 45.136.29.207\n",
            "Connecting to www.adrianbulat.com (www.adrianbulat.com)|45.136.29.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89843225 (86M) [application/octet-stream]\n",
            "Saving to: ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’\n",
            "\n",
            "Wav2Lip/face_detect 100%[===================>]  85.68M  24.8MB/s    in 4.5s    \n",
            "\n",
            "2023-11-02 19:21:49 (19.1 MB/s) - ‘Wav2Lip/face_detection/detection/sfd/s3fd.pth’ saved [89843225/89843225]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoVGMtjRZfeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4715dc-5d75-4914-fbdf-343175084ca1"
      },
      "source": [
        "!cp \"/content/gdrive/MyDrive/Projects/Wave2Lip/input/kennedy1min.mp4\" \"/content/gdrive/MyDrive/Projects/Wave2Lip/input/Cloned_voice.wav\" sample_data/\n",
        "!ls sample_data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anscombe.json\t\t      check.mp4\t\tmnist_test.csv\n",
            "california_housing_test.csv   Cloned_voice.wav\tmnist_train_small.csv\n",
            "california_housing_train.csv  kennedy1min.mp4\tREADME.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR5utmDMcSZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1782e8db-ffc5-41a4-d9c3-a1a2c12a2039"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/kennedy1min.mp4\" --audio \"/content/sample_data/Cloned_voice.wav\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 2398\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 225, in main\n",
            "    mel = audio.melspectrogram(wav)\n",
            "  File \"/content/Wav2Lip/audio.py\", line 47, in melspectrogram\n",
            "    S = _amp_to_db(_linear_to_mel(np.abs(D))) - hp.ref_level_db\n",
            "  File \"/content/Wav2Lip/audio.py\", line 95, in _linear_to_mel\n",
            "    _mel_basis = _build_mel_basis()\n",
            "  File \"/content/Wav2Lip/audio.py\", line 100, in _build_mel_basis\n",
            "    return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "TypeError: mel() takes 0 positional arguments but 2 positional arguments (and 3 keyword-only arguments) were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOAZvkszEOw"
      },
      "source": [
        "# use the \"files\" button on the left to download the result in the Wav2Lip/results/ folder."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45XW4SZAzIz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45bb8b2-cdb3-426a-fd2d-d79537dfb613"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"/content/sample_data/check.mp4\" --audio \"/content/sample_data/Cloned_voice.wav\" --pads 0 20 0 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference.\n",
            "Reading video frames...\n",
            "Number of frames available for inference: 2522\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Wav2Lip/inference.py\", line 280, in <module>\n",
            "    main()\n",
            "  File \"/content/Wav2Lip/inference.py\", line 225, in main\n",
            "    mel = audio.melspectrogram(wav)\n",
            "  File \"/content/Wav2Lip/audio.py\", line 47, in melspectrogram\n",
            "    S = _amp_to_db(_linear_to_mel(np.abs(D))) - hp.ref_level_db\n",
            "  File \"/content/Wav2Lip/audio.py\", line 95, in _linear_to_mel\n",
            "    _mel_basis = _build_mel_basis()\n",
            "  File \"/content/Wav2Lip/audio.py\", line 100, in _build_mel_basis\n",
            "    return librosa.filters.mel(hp.sample_rate, hp.n_fft, n_mels=hp.num_mels,\n",
            "TypeError: mel() takes 0 positional arguments but 2 positional arguments (and 3 keyword-only arguments) were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo-WnsxfbwTG"
      },
      "source": [
        "2.   Use resize_factor to reduce the video resolution, as there is a change you might get better results for lower resolution videos. Why? Because the model was trained on low resolution faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw0xFtZ2bsx8"
      },
      "source": [
        "!cd Wav2Lip && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face \"../sample_data/input_vid.mp4\" --audio \"../sample_data/input_audio.wav\" --resize_factor 2"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}